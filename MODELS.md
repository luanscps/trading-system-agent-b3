# üß† Modelos Ollama - Guia Completo

> Documenta√ß√£o dos 5 modelos usados no Trading Agent com nomes CORRETOS e verificados

---

## ‚ùå EM 01/02/2026 ESSES MODELOS N√ÉO EXISTEM

```bash
# ‚ùå N√ÉO USE ESSES NOMES
ollama pull deepseek-r1:7b-instruct-q4_K_M   # N√ÉO FUNCIONA
ollama pull gemma3:4b                        # USA gemma3:4b-it INSTEAD
```

---

## ‚úÖ MODELOS CORRETOS (01/02/2026)

### 1. SmolLM2 1.7B - An√°lise R√°pida

**Nome Correto:**
```bash
ollama pull smollm2:1.7b-instruct-q4_K_M
```

**Especifica√ß√µes:**
- **Tamanho**: 1.5GB
- **Lat√™ncia**: 300-500ms
- **Uso**: Sentimento r√°pido, classifica√ß√£o r√°pida
- **GPU**: N√£o obrigat√≥rio
- **Status**: ‚úÖ Funcional (verificado em 01/02/2026)

**Rodar:**
```bash
ollama run smollm2:1.7b-instruct-q4_K_M
```

---

### 2. Mistral 7B - An√°lise Detalhada

**Nome Correto:**
```bash
ollama pull mistral:7b-instruct-q4_K_M
```

**Especifica√ß√µes:**
- **Tamanho**: 4GB
- **Lat√™ncia**: 1-2 segundos
- **Uso**: An√°lise t√©cnica detalhada, interpreta√ß√£o gr√°ficos
- **GPU**: Recomendado 8GB VRAM
- **Status**: ‚úÖ Funcional (verificado em 01/02/2026)

**Rodar:**
```bash
ollama run mistral:7b-instruct-q4_K_M
```

---

### 3. DeepSeek-R1 8B - Racioc√≠nio Matem√°tico üéØ CR√çTICO

**Nome CORRETO (n√£o 7B):**
```bash
ollama pull deepseek-r1:8b
```

**Especifica√ß√µes:**
- **Tamanho**: 4.5GB
- **Lat√™ncia**: 2-3 segundos
- **Uso**: C√°lculo Sharpe Ratio, valida√ß√£o matem√°tica
- **GPU**: Recomendado 8GB VRAM
- **Status**: ‚úÖ Funcional (verificado em 01/02/2026)
- **AVISO**: N√£o existe vers√£o 7B com quantiza√ß√£o `-instruct-q4_K_M`

**Rodar:**
```bash
ollama run deepseek-r1:8b
```

**Alternativas (se 8B for lento):**
```bash
# Para m√°quinas com m√°s resources
ollama pull deepseek-r1:7b          # Vers√£o menor (se existir)
# ou
ollama pull mistral:7b-instruct-q4_K_M  # Fallback para Mistral
```

---

### 4. Qwen2.5-Coder 7B - Processamento de Dados

**Nome Correto:**
```bash
ollama pull qwen2.5-coder:7b-instruct-q4_K_M
```

**Especifica√ß√µes:**
- **Tamanho**: 5GB
- **Lat√™ncia**: 1-2 segundos
- **Uso**: Processamento de scripts, an√°lise de dados, gera√ß√£o de c√≥digo
- **GPU**: Recomendado 8GB VRAM
- **Status**: ‚úÖ Funcional (verificado em 01/02/2026)

**Rodar:**
```bash
ollama run qwen2.5-coder:7b-instruct-q4_K_M
```

---

### 5. Gemma 3 4B - An√°lise Multimodal üéØ CR√çTICO

**Nome CORRETO (com `-it`):**
```bash
ollama pull gemma3:4b-it
```

**Especifica√ß√µes:**
- **Tamanho**: 2.5GB
- **Lat√™ncia**: 800ms
- **Uso**: An√°lise de sentimento, suporte multimodal (texto + imagens)
- **GPU**: Recomendado 6GB VRAM
- **Status**: ‚úÖ Funcional (verificado em 01/02/2026)
- **AVISO**: N√£o use `gemma3:4b` (use `gemma3:4b-it`)

**Rodar:**
```bash
ollama run gemma3:4b-it
```

**Op√ß√µes Gemma 3 dispon√≠veis:**
```bash
ollama pull gemma3:270m    # Ultra-leve (32KB context)
ollama pull gemma3:1b      # Muito leve (32K context)
ollama pull gemma3:4b-it   # ‚úÖ RECOMENDADO (128K context)
ollama pull gemma3:12b     # Mais poderoso (128K context)
ollama pull gemma3:27b     # Very large (128K context)
```

---

## üìÉ Resumo dos Nomes Corretos

| # | Modelo | Nome Ollama Correto | ‚ùå ERRADO | Tamanho |
|---|--------|---------------------|----------|----------|
| 1 | SmolLM2 1.7B | `smollm2:1.7b-instruct-q4_K_M` | N/A | 1.5GB |
| 2 | Mistral 7B | `mistral:7b-instruct-q4_K_M` | N/A | 4GB |
| 3 | DeepSeek-R1 8B | `deepseek-r1:8b` | `deepseek-r1:7b-instruct-q4_K_M` | 4.5GB |
| 4 | Qwen2.5 7B | `qwen2.5-coder:7b-instruct-q4_K_M` | N/A | 5GB |
| 5 | Gemma 3 4B | `gemma3:4b-it` | `gemma3:4b` | 2.5GB |

**Total**: 17.5GB em disco

---

## üöÖ Como Baixar Todos (Correto)

```bash
#!/bin/bash
# Script para baixar TODOS os modelos com nomes corretos

echo "üöÖ Baixando 5 modelos para Trading Agent..."

ollama pull smollm2:1.7b-instruct-q4_K_M
echo "‚úÖ SmolLM2 1.7B"

ollama pull mistral:7b-instruct-q4_K_M
echo "‚úÖ Mistral 7B"

ollama pull deepseek-r1:8b
echo "‚úÖ DeepSeek-R1 8B"

ollama pull qwen2.5-coder:7b-instruct-q4_K_M
echo "‚úÖ Qwen2.5-Coder 7B"

ollama pull gemma3:4b-it
echo "‚úÖ Gemma 3 4B"

echo "üöÄ Conclu√≠do! 17.5GB baixados"
ollama list
```

---

## üêõ Problemas Comuns

### Erro: "Model not found: deepseek-r1:7b-instruct-q4_K_M"

**Causa**: Nome errado (7B com quantiza√ß√£o n√£o existe)  
**Solu√ß√£o**: Use `deepseek-r1:8b`

```bash
# ‚ùå ERRADO
ollama pull deepseek-r1:7b-instruct-q4_K_M

# ‚úÖ CORRETO
ollama pull deepseek-r1:8b
```

### Erro: "Model not found: gemma3:4b"

**Causa**: Nome incompleto (falta `-it`)  
**Solu√ß√£o**: Use `gemma3:4b-it`

```bash
# ‚ùå ERRADO
ollama pull gemma3:4b

# ‚úÖ CORRETO
ollama pull gemma3:4b-it
```

### Verificar Modelos Instalados

```bash
ollama list
```

**Sa√≠da esperada:**
```
NAME                               ID              SIZE      MODIFIED
smollm2:1.7b-instruct-q4_K_M      abcd1234...     1.5GB     2 hours ago
mistral:7b-instruct-q4_K_M        efgh5678...     4.0GB     2 hours ago
deepseek-r1:8b                    ijkl9012...     4.5GB     2 hours ago
qwen2.5-coder:7b-instruct-q4_K_M  mnop3456...     5.0GB     2 hours ago
gemma3:4b-it                       qrst7890...     2.5GB     2 hours ago
```

---

## üåê Fonte de Verifica√ß√£o

- [Ollama Model Library](https://ollama.com/library)
- [DeepSeek-R1 no Ollama](https://ollama.com/library/deepseek-r1)
- [Gemma 3 no Ollama](https://ollama.com/library/gemma3)

**√öltima verifica√ß√£o**: 01/02/2026

---

## üìù Refer√™ncia R√°pida (.env)

```bash
# Nomes corretos para .env
OLLAMA_MODEL_FAST=smollm2:1.7b-instruct-q4_K_M
OLLAMA_MODEL_STANDARD=mistral:7b-instruct-q4_K_M
OLLAMA_MODEL_REASONING=deepseek-r1:8b
OLLAMA_MODEL_CODER=qwen2.5-coder:7b-instruct-q4_K_M
OLLAMA_MODEL_SENTIMENT=gemma3:4b-it
```

---

**üöÄ Use esses nomes exatos ou falhar√°!**
